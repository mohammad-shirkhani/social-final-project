import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import networkx as nx
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tqdm import tqdm
from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.vec_env import DummyVecEnv
from gym import spaces
import gym
import random
from collections import deque
import matplotlib.pyplot as plt
import warnings
import json
import math

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
warnings.filterwarnings('ignore')
torch.manual_seed(42)
np.random.seed(42)

# 1. Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
print("ğŸ“‚ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
ratings = pd.read_csv('C:/Users/jalal/Downloads/COMPER/ml-latest-small/ratings.csv')
movies = pd.read_csv('C:/Users/jalal/Downloads/COMPER/ml-latest-small/movies.csv')
print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯Ù†Ø¯: {len(ratings)} Ø±ÛŒØªÛŒÙ†Ú¯ØŒ {len(movies)} ÙÛŒÙ„Ù…")

# 2. Ø§ÛŒØ¬Ø§Ø¯ Ù†Ú¯Ø§Ø´Øª Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø§Ù†Ø¯ÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÙˆØ³ØªÙ‡
print("ğŸ”„ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ú¯Ø§Ø´Øª Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§...")
user_ids = ratings['userId'].unique()
user_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}
item_ids = ratings['movieId'].unique()
item_to_idx = {item_id: idx for idx, item_id in enumerate(item_ids)}

# Ø§ÙØ²ÙˆØ¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø§Ù†Ø¯ÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÙˆØ³ØªÙ‡
ratings['user_idx'] = ratings['userId'].map(user_to_idx)
ratings['item_idx'] = ratings['movieId'].map(item_to_idx)

print(f"ğŸ”¢ {len(user_ids)} Ú©Ø§Ø±Ø¨Ø± Ùˆ {len(item_ids)} ÙÛŒÙ„Ù… Ù†Ú¯Ø§Ø´Øª Ø´Ø¯Ù†Ø¯")

# 3. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øªâ€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù†Ø¯ÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÙˆØ³ØªÙ‡
print("ğŸ§® Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ...")
rating_matrix = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)

print("ğŸ‘¥ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†...")
user_corr = rating_matrix.T.corr(method='pearson')
user_corr.index.name = 'userA'
user_corr.columns.name = 'userB'
user_sim = user_corr.stack().reset_index(name='correlation')
user_sim = user_sim[
    (user_sim['correlation'] > 0.5) & 
    (user_sim['userA'] != user_sim['userB']) &
    (user_sim['userA'] < user_sim['userB'])
].reset_index(drop=True)
print(f"âœ… {len(user_sim)} Ø¬ÙØª Ú©Ø§Ø±Ø¨Ø± Ù…Ø´Ø§Ø¨Ù‡")

print("ğŸ¬ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§...")
item_corr = rating_matrix.corr(method='pearson')
item_corr.index.name = 'itemA'
item_corr.columns.name = 'itemB'
item_sim = item_corr.stack().reset_index(name='correlation')
item_sim = item_sim[
    (item_sim['correlation'] > 0.5) & 
    (item_sim['itemA'] != item_sim['itemB']) &
    (item_sim['itemA'] < item_sim['itemB'])
].reset_index(drop=True)
print(f"âœ… {len(item_sim)} Ø¬ÙØª ÙÛŒÙ„Ù… Ù…Ø´Ø§Ø¨Ù‡")

# 4. Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ù‡Ù…Ú©Ø§Ø±ÛŒ Ø¨Ø§ Ø§Ù†Ø¯ÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÙˆØ³ØªÙ‡
print("ğŸ•¸ï¸ Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ù‡Ù…Ú©Ø§Ø±ÛŒ...")
G = nx.Graph()

# Ø§ÙØ²ÙˆØ¯Ù† Ú¯Ø±Ù‡â€ŒÙ‡Ø§
user_nodes = ratings['user_idx'].unique()
item_nodes = ratings['item_idx'].unique()
G.add_nodes_from(user_nodes, node_type='user')
G.add_nodes_from(item_nodes, node_type='item')
print(f"âœ… {len(user_nodes)} Ú©Ø§Ø±Ø¨Ø± Ùˆ {len(item_nodes)} ÙÛŒÙ„Ù… Ø¨Ù‡ Ú¯Ø±Ø§Ù Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù†Ø¯")

# Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø²
for _, row in tqdm(ratings.iterrows(), total=len(ratings), desc="ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø²"):
    G.add_edge(row['user_idx'], row['item_idx'], 
               relation_type=f'Rated_{int(row["rating"])}',
               weight=row['rating'])

# Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
if not user_sim.empty:
    for _, row in tqdm(user_sim.iterrows(), total=len(user_sim), desc="Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†"):
        G.add_edge(row['userA'], row['userB'], 
                   relation_type='UserSim',
                   weight=row['correlation'])

# Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ø§Ù‡Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§
if not item_sim.empty:
    for _, row in tqdm(item_sim.iterrows(), total=len(item_sim), desc="Ø´Ø¨Ø§Ù‡Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§"):
        G.add_edge(row['itemA'], row['itemB'], 
                   relation_type='ItemSim',
                   weight=row['correlation'])

print(f"âœ… Ú¯Ø±Ø§Ù Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯: {G.number_of_nodes()} Ú¯Ø±Ù‡ØŒ {G.number_of_edges()} ÛŒØ§Ù„")

# 5. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØªØ§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
def extract_meta_paths(G, user_idx, item_idx, max_paths=10, max_length=4):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØªØ§ Ø¨ÛŒÙ† Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø¢ÛŒØªÙ… Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ BFS"""
    if user_idx not in G or item_idx not in G:
        return []
    
    try:
        paths = []
        queue = deque([(user_idx, [user_idx])])
        visited = set()
        
        while queue and len(paths) < max_paths:
            node, path = queue.popleft()
            visited.add(node)
            
            if node == item_idx and len(path) > 1:
                paths.append(path)
                continue
                
            if len(path) >= max_length:
                continue
                
            for neighbor in G.neighbors(node):
                if neighbor not in path and neighbor not in visited:
                    new_path = path + [neighbor]
                    queue.append((neighbor, new_path))
        
        return paths
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±: {e}")
        return []

# 6. Ù…Ø¯Ù„ COMPER Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ ØªÙØ³ÛŒØ±Ù¾Ø°ÛŒØ±ÛŒ
class AdvancedCOMPER(nn.Module):
    def __init__(self, num_users, num_items, relation2idx, emb_dim=64, lstm_dim=64):
        super(AdvancedCOMPER, self).__init__()
        self.relation2idx = relation2idx
        
        # Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ø³Ø§Ø²ÛŒ
        self.user_emb = nn.Embedding(num_users, emb_dim)
        self.item_emb = nn.Embedding(num_items, emb_dim)
        self.relation_emb = nn.Embedding(len(relation2idx), emb_dim)
        self.node_type_emb = nn.Embedding(2, emb_dim)  # 0: user, 1: item
        
        # Ù„Ø§ÛŒÙ‡ LSTM Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø³ÛŒØ±Ù‡Ø§
        self.lstm = nn.LSTM(3 * emb_dim, lstm_dim, batch_first=True)
        
        # Ù…Ú©Ø§Ù†ÛŒØ²Ù… ØªÙˆØ¬Ù‡ Ù¾ÙˆÛŒØ§
        self.attention = nn.Sequential(
            nn.Linear(lstm_dim + 2 * emb_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 1)
        )
        
        # Ù„Ø§ÛŒÙ‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        self.fc = nn.Sequential(
            nn.Linear(lstm_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1)
        )
        
        # Ù„Ø§ÛŒÙ‡ Ø§ÛŒÙ…Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªÙ‚ÙˆÛŒØªÛŒ
        self.safety_layer = nn.Sequential(
            nn.Linear(emb_dim * 2, 32),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
        # Ù„Ø§ÛŒÙ‡ Ø§Ø±Ø²Ø´ Ùˆ Ù…Ø²ÛŒØª Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Dueling DQN
        self.value_stream = nn.Sequential(
            nn.Linear(lstm_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
        
        self.advantage_stream = nn.Sequential(
            nn.Linear(lstm_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
    
    def forward(self, user_idx, item_idx, paths):
        # Ø¬Ø§Ø³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø¢ÛŒØªÙ…
        u_emb = self.user_emb(user_idx)
        i_emb = self.item_emb(item_idx)
        
        path_embs = []
        for path in paths:
            seq = []
            for i in range(len(path) - 1):
                node = path[i]
                next_node = path[i+1]
                
                # Ø¬Ø§Ø³Ø§Ø²ÛŒ Ú¯Ø±Ù‡
                if G.nodes[node].get('node_type', '') == 'user':
                    node_emb = self.user_emb(torch.tensor([node], device=user_idx.device, dtype=torch.long))
                    node_type = torch.tensor([0], device=user_idx.device, dtype=torch.long)
                else:
                    node_emb = self.item_emb(torch.tensor([node], device=user_idx.device, dtype=torch.long))
                    node_type = torch.tensor([1], device=user_idx.device, dtype=torch.long)
                
                # Ø¬Ø§Ø³Ø§Ø²ÛŒ Ø±Ø§Ø¨Ø·Ù‡
                rel_type = G.edges[node, next_node].get('relation_type', 'Rated_3')
                rel_idx = self.relation2idx.get(rel_type, 0)
                rel_emb = self.relation_emb(torch.tensor([rel_idx], device=user_idx.device, dtype=torch.long))
                
                # ØªØ±Ú©ÛŒØ¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø­Ø°Ù Ø¨Ø¹Ø¯ Ø§Ø¶Ø§ÙÛŒ
                node_emb = node_emb.squeeze(0)
                node_type_emb = self.node_type_emb(node_type).squeeze(0)
                rel_emb = rel_emb.squeeze(0)
                
                features = torch.cat([node_emb, node_type_emb, rel_emb], dim=-1)
                seq.append(features)
            
            if not seq:
                continue
                
            # Ø§ÛŒØ¬Ø§Ø¯ ØªØ§Ù†Ø³ÙˆØ± 3 Ø¨Ø¹Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ LSTM
            seq_tensor = torch.stack(seq)  # Ø´Ú©Ù„: [sequence_length, features]
            seq_tensor = seq_tensor.unsqueeze(0)  # Ø´Ú©Ù„: [1, sequence_length, features] - 3 Ø¨Ø¹Ø¯ÛŒ
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ LSTM
            _, (h_n, _) = self.lstm(seq_tensor)
            path_emb = h_n[-1]  # Ø¢Ø®Ø±ÛŒÙ† hidden state Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ù„Ø§ÛŒÙ‡
            path_embs.append(path_emb)
        
        if not path_embs:
            return torch.zeros(1, device=user_idx.device), torch.zeros(1, device=user_idx.device)
            
        path_embs = torch.cat(path_embs, dim=0)
        context = torch.cat([u_emb, i_emb], dim=-1).repeat(len(path_embs), 1)
        att_input = torch.cat([path_embs, context], dim=1)
        att_scores = self.attention(att_input)
        att_weights = F.softmax(att_scores, dim=0)
        
        # ØªØ¬Ù…Ø¹ Ø¨Ø§ ØªÙˆØ¬Ù‡
        aggregated = torch.sum(att_weights * path_embs, dim=0)
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ù…Ø¹Ù…Ø§Ø±ÛŒ Dueling
        value = self.value_stream(aggregated)
        advantage = self.advantage_stream(aggregated)
        q_value = value + (advantage - advantage.mean())
        
        # Ø§Ø¹Ù…Ø§Ù„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ…Ù†ÛŒ
        safety = self.safety_layer(torch.cat([u_emb, i_emb], dim=-1))
        prediction = q_value * safety
        
        return prediction, att_weights

# 7. Ù…Ø­ÛŒØ· ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªÙ‚ÙˆÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡â€ŒÚ¯Ø±
class AdvancedRecSysEnv(gym.Env):
    def __init__(self, model, data, G, relation2idx, feature_names):
        super(AdvancedRecSysEnv, self).__init__()
        self.model = model
        self.data = data
        self.G = G
        self.relation2idx = relation2idx
        self.feature_names = feature_names
        
        # ØªØ¹Ø±ÛŒÙ ÙØ¶Ø§ÛŒ Ø­Ø§Ù„Øª Ùˆ Ø¹Ù…Ù„
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(128,))  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ù‡ 128 Ø¨Ø¹Ø¯
        self.action_space = spaces.MultiBinary(5)  # Ø§Ù†ØªØ®Ø§Ø¨ Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ù…Ø³ÛŒØ±
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÛŒÙ…Ù†ÛŒ
        self.safety_constraints = {
            'min_rating': 1.0,
            'max_rating': 5.0,
            'min_paths': 1
        }
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§Ø¯Ø§Ø´ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡)
        self.reward_weights = {
            'accuracy': 2.0,  # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù‡Ù…ÛŒØª Ø¯Ù‚Øª
            'diversity': 0.3, # Ú©Ø§Ù‡Ø´ Ø§Ù‡Ù…ÛŒØª ØªÙ†ÙˆØ¹
            'safety': 0.1,   # Ú©Ø§Ù‡Ø´ Ø§Ù‡Ù…ÛŒØª Ø§ÛŒÙ…Ù†ÛŒ
            'simplicity': 0.05 # Ú©Ø§Ù‡Ø´ Ø§Ù‡Ù…ÛŒØª Ø³Ø§Ø¯Ú¯ÛŒ
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙØ³ÛŒØ±Ù¾Ø°ÛŒØ±ÛŒ
        self.explanation_history = []
        
    def reset(self):
        self.current_idx = 0
        self.current_step = 0
        self.selected_paths_history = []
        return self._get_state()
    
    def step(self, action):
        self.current_step += 1
        row = self.data.iloc[self.current_idx]
        user_idx = torch.tensor([row['user_idx']], device='cpu', dtype=torch.long)
        item_idx = torch.tensor([row['item_idx']], device='cpu', dtype=torch.long)
        true_rating = row['rating']
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ù…Ú©Ù†
        paths = extract_meta_paths(self.G, user_idx.item(), item_idx.item(), max_paths=10, max_length=4)
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø³ÛŒØ±Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù„ Ø¹Ø§Ù…Ù„
        selected_paths = [p for i, p in enumerate(paths) if i < len(action) and action[i] == 1]
        
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù…Ø³ÛŒØ±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² Ø§ÙˆÙ„ÛŒÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        if not selected_paths and paths:
            selected_paths = paths[:3]
        
        # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§
        self.selected_paths_history.append({
            'user': user_idx.item(),
            'item': item_idx.item(),
            'selected_paths': selected_paths,
            'all_paths': paths
        })
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ù…ØªÛŒØ§Ø²
        with torch.no_grad():
            try:
                pred, _ = self.model(user_idx, item_idx, selected_paths)
                rmse = torch.sqrt(F.mse_loss(pred, torch.tensor([true_rating], device='cpu'))).item()
                pred_rating = pred.item()
            except Exception as e:
                print(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {e}")
                rmse = 3.0
                pred_rating = 3.0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù¾Ø§Ø¯Ø§Ø´ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡)
        reward_components = self._calculate_reward_components(
            selected_paths, true_rating, pred_rating, rmse
        )
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ø§Ø¯Ø§Ø´ Ù†Ù‡Ø§ÛŒÛŒ
        total_reward = sum(
            self.reward_weights[k] * reward_components[k] 
            for k in self.reward_weights
        )
        
        # Ø§ÛŒØ¬Ø§Ø¯ ØªÙØ³ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡
        explanation = self._generate_explanation(user_idx, item_idx, selected_paths, true_rating, pred_rating)
        self.explanation_history.append(explanation)
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³
        self.current_idx = (self.current_idx + 1) % len(self.data)
        done = self.current_step >= 200  # Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø±Ø§Ø­Ù„
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ MAE Ùˆ RMSE
        result = {
            'true_rating': true_rating,
            'pred_rating': pred_rating,
            'rmse': rmse,
            'mae': abs(true_rating - pred_rating)
        }
        
        return self._get_state(), total_reward, done, result
    
    def _get_state(self):
        row = self.data.iloc[self.current_idx]
        user_idx = torch.tensor([row['user_idx']], device='cpu', dtype=torch.long)
        item_idx = torch.tensor([row['item_idx']], device='cpu', dtype=torch.long)
        with torch.no_grad():
            u_emb = self.model.user_emb(user_idx).cpu().numpy().flatten()
            i_emb = self.model.item_emb(item_idx).cpu().numpy().flatten()
        return np.concatenate([u_emb, i_emb])  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ…Ø§Ù… Ø§Ø¨Ø¹Ø§Ø¯
    
    def _calculate_reward_components(self, selected_paths, true_rating, pred_rating, rmse):
        # Ø¯Ù‚Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡)
        accuracy = 1.0 / (1.0 + rmse)  # Ù…Ø¹Ú©ÙˆØ³ RMSE
        
        # Ù¾Ø§Ø¯Ø§Ø´ Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ù‚ÛŒÙ‚
        if abs(pred_rating - true_rating) < 0.5:
            accuracy += 1.0
        
        # ØªÙ†ÙˆØ¹ Ù…Ø³ÛŒØ±Ù‡Ø§ (SID)
        sid = self._calculate_sid(selected_paths) if selected_paths else 0.0
        
        # Ø§ÛŒÙ…Ù†ÛŒ (Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø±ÛŒØªÛŒÙ†Ú¯)
        safety_penalty = 0
        if pred_rating < self.safety_constraints['min_rating']:
            safety_penalty = -0.5 * (self.safety_constraints['min_rating'] - pred_rating)
        elif pred_rating > self.safety_constraints['max_rating']:
            safety_penalty = -0.5 * (pred_rating - self.safety_constraints['max_rating'])
        
        # Ø³Ø§Ø¯Ú¯ÛŒ (ØªØ¹Ø¯Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡)
        simplicity = -0.05 * len(selected_paths)  # Ø¬Ø±ÛŒÙ…Ù‡ Ú©Ù…ØªØ±
        
        return {
            'accuracy': accuracy,
            'diversity': sid,
            'safety': safety_penalty,
            'simplicity': simplicity
        }
    
    def _calculate_sid(self, paths):
        pattern_counts = {}
        for path in paths:
            pattern = []
            for i in range(len(path) - 1):
                rel = self.G.edges[path[i], path[i+1]].get('relation_type', 'Rated_3')[:3]
                pattern.append(rel)
            pattern_str = '-'.join(pattern)
            pattern_counts[pattern_str] = pattern_counts.get(pattern_str, 0) + 1
        
        n = len(paths)
        sid = 1 - sum([count*(count-1) for count in pattern_counts.values()]) / (n*(n-1)) if n > 1 else 0
        return sid
    
    def _generate_explanation(self, user_idx, item_idx, paths, true_rating, pred_rating):
        # ØªÙØ³ÛŒØ± Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù…Ø³ÛŒØ±Ù‡Ø§
        path_explanations = []
        for i, path in enumerate(paths):
            exp = []
            for j in range(len(path) - 1):
                from_node = path[j]
                to_node = path[j+1]
                rel = self.G.edges[from_node, to_node].get('relation_type', 'Rated_3')
                
                if 'UserSim' in rel:
                    exp.append(f"Ú©Ø§Ø±Ø¨Ø± {from_node} â†â†’ Ú©Ø§Ø±Ø¨Ø± {to_node}")
                elif 'ItemSim' in rel:
                    exp.append(f"ÙÛŒÙ„Ù… {from_node} â†â†’ ÙÛŒÙ„Ù… {to_node}")
                elif 'Rated' in rel:
                    rating = rel.split('_')[-1]
                    if G.nodes[from_node].get('node_type') == 'user':
                        exp.append(f"Ú©Ø§Ø±Ø¨Ø± {from_node} â†’ ÙÛŒÙ„Ù… {to_node} ({rating})")
                    else:
                        exp.append(f"ÙÛŒÙ„Ù… {from_node} â†’ Ú©Ø§Ø±Ø¨Ø± {to_node} ({rating})")
            path_explanations.append(" â†’ ".join(exp))
        
        return {
            'user': user_idx.item(),
            'item': item_idx.item(),
            'true_rating': true_rating,
            'pred_rating': pred_rating,
            'paths': path_explanations,
            'num_paths': len(paths)
        }
    
    def save_explanations(self, filename):
        """Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ ØªÙØ³ÛŒØ±Ù‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.explanation_history, f, ensure_ascii=False, indent=2)

# 8. Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³ÛŒØ³ØªÙ…
def train_comper_with_rl():
    # Ù…Ø³ÛŒØ± Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
    BASE_DIR = "C:/Users/jalal/Downloads/COMPER/ml-latest-small"
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
    print("âš™ï¸ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"âš¡ Ø¯Ø³ØªÚ¯Ø§Ù‡: {device}")
    
    # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„
    num_users = len(user_ids)
    num_items = len(item_ids)
    relation_types = list(set(d['relation_type'] for _, _, d in G.edges(data=True)))
    relation2idx = {rel: idx for idx, rel in enumerate(relation_types)}
    feature_names = [f'Emb_{i}' for i in range(64)]  # Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ emb_dim=64
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)
    print(f"âœ‚ï¸ ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡: Ø¢Ù…ÙˆØ²Ø´={len(train_data)}, ØªØ³Øª={len(test_data)}")
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ COMPER - Ø§Ø±Ø³Ø§Ù„ relation2idx Ø¨Ù‡ Ù…Ø¯Ù„
    model = AdvancedCOMPER(
        num_users, 
        num_items, 
        relation2idx,  # Ø§Ø±Ø³Ø§Ù„ relation2idx
        emb_dim=64, 
        lstm_dim=64
    ).to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)
    
    # Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡
    print("ğŸ”¥ Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡...")
    train_data_small = train_data.sample(2000, random_state=42)  # Ø§ÙØ²Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡
    
    for epoch in range(3):  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ù‡ 5 Ø¯ÙˆØ±Ù‡
        epoch_loss = 0
        processed_count = 0
        progress_bar = tqdm(train_data_small.iterrows(), total=len(train_data_small), desc=f"Ø¯ÙˆØ±Ù‡ {epoch+1}/3")
        for _, row in progress_bar:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø§Ù†Ø¯ÛŒØ³ Ù¾ÛŒÙˆØ³ØªÙ‡
            user_idx = torch.tensor([row['user_idx']], device=device, dtype=torch.long)
            item_idx = torch.tensor([row['item_idx']], device=device, dtype=torch.long)
            true_rating = torch.tensor([row['rating']], dtype=torch.float, device=device)
            
            paths = extract_meta_paths(G, user_idx.item(), item_idx.item(), max_paths=5, max_length=4)
            
            # Ø§Ú¯Ø± Ù…Ø³ÛŒØ±ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø§Ø² Ø­Ù„Ù‚Ù‡ Ø¹Ø¨ÙˆØ± Ú©Ù†
            if not paths:
                continue
                
            try:
                pred, _ = model(user_idx, item_idx, paths)
                loss = F.mse_loss(pred, true_rating)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                processed_count += 1
                progress_bar.set_postfix(loss=f"{loss.item():.4f}")
            except Exception as e:
                print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´: {e}")
        
        if processed_count > 0:
            avg_loss = epoch_loss / processed_count
        else:
            avg_loss = 0
            
        scheduler.step()
        print(f"Ø¯ÙˆØ±Ù‡ {epoch+1} - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø®Ø·Ø§: {avg_loss:.4f}")
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ÛŒØ· ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªÙ‚ÙˆÛŒØªÛŒ
    print("ğŸ¤– Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ÛŒØ· RL...")
    env = AdvancedRecSysEnv(
        model, 
        train_data_small,
        G,
        relation2idx,
        feature_names
    )
    env = DummyVecEnv([lambda: env])
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø¹Ø§Ù…Ù„ RL (PPO)
    rl_model = PPO(
        "MlpPolicy",
        env,
        verbose=1,
        learning_rate=0.0003,
        n_steps=256,  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
        batch_size=64,
        n_epochs=3,
        device=device
    )
    
    # Ø¢Ù…ÙˆØ²Ø´ Ø¹Ø§Ù…Ù„ RL
    print("ğŸš€ Ø¢Ù…ÙˆØ²Ø´ Ø¹Ø§Ù…Ù„ RL...")
    rl_model.learn(total_timesteps=5000)  # Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø±Ø§Ø­Ù„ Ø¢Ù…ÙˆØ²Ø´
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡
    rl_model_path = os.path.join(BASE_DIR, "comper_rl_model")
    rl_model.save(rl_model_path)
    print(f"ğŸ’¾ Ù…Ø¯Ù„ RL Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {rl_model_path}")
    
    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
    print("ğŸ§ª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„...")
    test_rewards = []
    all_true_ratings = []
    all_pred_ratings = []
    
    for i in tqdm(range(50), desc="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ"):  # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù¾ÛŒØ²ÙˆØ¯Ù‡Ø§ÛŒ ØªØ³Øª
        obs = env.reset()
        done = False
        total_reward = 0
        
        while not done:
            action, _ = rl_model.predict(obs)
            obs, reward, done, info = env.step(action)
            total_reward += reward
            
            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ MAE Ùˆ RMSE
            all_true_ratings.append(info[0]['true_rating'])
            all_pred_ratings.append(info[0]['pred_rating'])
        
        test_rewards.append(total_reward)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
    avg_reward = np.mean(test_rewards)
    std_reward = np.std(test_rewards)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ MAE Ùˆ RMSE
    mae = mean_absolute_error(all_true_ratings, all_pred_ratings)
    rmse = math.sqrt(mean_squared_error(all_true_ratings, all_pred_ratings))
    
    print(f"âœ… Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù¾Ø§Ø¯Ø§Ø´ ØªØ³Øª: {avg_reward:.4f} Â± {std_reward:.4f}")
    print(f"ğŸ“Š Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ:")
    print(f"  - MAE: {mae:.4f}")
    print(f"  - RMSE: {rmse:.4f}")
    
    # Ø°Ø®ÛŒØ±Ù‡ ØªÙØ³ÛŒØ±Ù‡Ø§
    explanation_path = os.path.join(BASE_DIR, "path_explanations.json")
    env.envs[0].save_explanations(explanation_path)
    print(f"ğŸ’¾ ØªÙØ³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯ Ø¯Ø±: {explanation_path}")
    
    # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
    generate_final_report(model, rl_model, test_rewards, all_true_ratings, all_pred_ratings, BASE_DIR)

def generate_final_report(model, rl_model, test_rewards, true_ratings, pred_ratings, base_dir):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§"""
    print("ğŸ“Š ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ...")
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
    avg_reward = np.mean(test_rewards)
    std_reward = np.std(test_rewards)
    mae = mean_absolute_error(true_ratings, pred_ratings)
    rmse = math.sqrt(mean_squared_error(true_ratings, pred_ratings))
    
    # Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø§Ø¯Ø§Ø´â€ŒÙ‡Ø§
    plt.figure(figsize=(12, 8))
    plt.plot(test_rewards)
    plt.title("Ù¾Ø§Ø¯Ø§Ø´â€ŒÙ‡Ø§ÛŒ ØªØ³Øª Ø¯Ø± Ø·ÙˆÙ„ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ", fontsize=14)
    plt.xlabel("Ø§Ù¾ÛŒØ²ÙˆØ¯ ØªØ³Øª", fontsize=12)
    plt.ylabel("Ù¾Ø§Ø¯Ø§Ø´", fontsize=12)
    plt.grid(True)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú©
    window_size = 5
    moving_avg = np.convolve(test_rewards, np.ones(window_size)/window_size, mode='valid')
    plt.plot(range(window_size-1, len(test_rewards)), moving_avg, 'r-', linewidth=2)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±
    plot_path = os.path.join(base_dir, "test_rewards.png")
    plt.savefig(plot_path)
    print(f"ğŸ’¾ Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø§Ø¯Ø§Ø´â€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {plot_path}")
    
    # Ù†Ù…ÙˆØ¯Ø§Ø± ØªÙˆØ²ÛŒØ¹ Ø®Ø·Ø§Ù‡Ø§
    errors = [abs(t - p) for t, p in zip(true_ratings, pred_ratings)]
    plt.figure(figsize=(12, 8))
    plt.hist(errors, bins=30, alpha=0.7, color='blue')
    plt.title("ØªÙˆØ²ÛŒØ¹ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", fontsize=14)
    plt.xlabel("Ø®Ø·Ø§ÛŒ Ù…Ø·Ù„Ù‚ (MAE)", fontsize=12)
    plt.ylabel("ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§", fontsize=12)
    plt.grid(True)
    error_dist_path = os.path.join(base_dir, "error_distribution.png")
    plt.savefig(error_dist_path)
    print(f"ğŸ’¾ Ù†Ù…ÙˆØ¯Ø§Ø± ØªÙˆØ²ÛŒØ¹ Ø®Ø·Ø§Ù‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {error_dist_path}")
    
    # Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÛŒØªÛŒÙ†Ú¯ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡
    plt.figure(figsize=(12, 8))
    plt.scatter(true_ratings, pred_ratings, alpha=0.3)
    plt.plot([0, 5], [0, 5], 'r--')
    plt.title("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÛŒØªÛŒÙ†Ú¯ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡", fontsize=14)
    plt.xlabel("Ø±ÛŒØªÛŒÙ†Ú¯ ÙˆØ§Ù‚Ø¹ÛŒ", fontsize=12)
    plt.ylabel("Ø±ÛŒØªÛŒÙ†Ú¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡", fontsize=12)
    plt.grid(True)
    comparison_path = os.path.join(base_dir, "rating_comparison.png")
    plt.savefig(comparison_path)
    print(f"ğŸ’¾ Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÛŒØªÛŒÙ†Ú¯â€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {comparison_path}")
    
    # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„
    weights_path = os.path.join(base_dir, "comper_model_weights.pth")
    torch.save(model.state_dict(), weights_path)
    
    # Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ
    report = f"""
    ================== Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø³ÛŒØ³ØªÙ… COMPER ==================
    Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒØ³ØªÙ…:
      - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù¾Ø§Ø¯Ø§Ø´ ØªØ³Øª: {avg_reward:.4f} Â± {std_reward:.4f}
      - Ø­Ø¯Ø§Ú©Ø«Ø± Ù¾Ø§Ø¯Ø§Ø´: {np.max(test_rewards):.4f}
      - Ø­Ø¯Ø§Ù‚Ù„ Ù¾Ø§Ø¯Ø§Ø´: {np.min(test_rewards):.4f}
      - MAE (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø®Ø·Ø§ÛŒ Ù…Ø·Ù„Ù‚): {mae:.4f}
      - RMSE (Ø±ÛŒØ´Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø±Ø¨Ø¹Ø§Øª Ø®Ø·Ø§): {rmse:.4f}
    
    Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„:
      - Ù…Ø¹Ù…Ø§Ø±ÛŒ: COMPER Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ LSTM Ùˆ ØªÙˆØ¬Ù‡
      - Ø§Ø¨Ø¹Ø§Ø¯ Ø¬Ø§Ø³Ø§Ø²ÛŒ: 64
      - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„: {sum(p.numel() for p in model.parameters())}
      - Ù†ÙˆØ¹ RL: PPO Ø¨Ø§ Ø³ÛŒØ§Ø³Øª MLP
    
    Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§:
      - Ù…Ø¯Ù„ RL: {os.path.join(base_dir, "comper_rl_model.zip")}
      - ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ COMPER: {weights_path}
      - ØªÙØ³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø³ÛŒØ±: {os.path.join(base_dir, "path_explanations.json")}
      - Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø§Ø¯Ø§Ø´â€ŒÙ‡Ø§: {plot_path}
      - Ù†Ù…ÙˆØ¯Ø§Ø± ØªÙˆØ²ÛŒØ¹ Ø®Ø·Ø§Ù‡Ø§: {error_dist_path}
      - Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÛŒØªÛŒÙ†Ú¯â€ŒÙ‡Ø§: {comparison_path}
    =============================================================
    """
    print(report)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ
    report_path = os.path.join(base_dir, "final_report.txt")
    with open(report_path, "w", encoding='utf-8') as f:
        f.write(report)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ CSV
    eval_results = pd.DataFrame({
        'true_rating': true_ratings,
        'pred_rating': pred_ratings,
        'error': [abs(t - p) for t, p in zip(true_ratings, pred_ratings)]
    })
    eval_path = os.path.join(base_dir, "evaluation_results.csv")
    eval_results.to_csv(eval_path, index=False)
    print(f"ğŸ’¾ Ù†ØªØ§ÛŒØ¬ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {eval_path}")
    
    print(f"ğŸ’¾ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {report_path}")

# Ø§Ø¬Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…
if __name__ == "__main__":
    train_comper_with_rl()