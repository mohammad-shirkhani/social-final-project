import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import networkx as nx
from collections import deque
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tqdm import tqdm
from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.vec_env import DummyVecEnv
from gym import spaces
import gym
import warnings
import gc

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
warnings.filterwarnings('ignore')
pd.options.mode.chained_assignment = None
torch.manual_seed(42)
np.random.seed(42)

# 1. Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
print("ğŸ“‚ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
ratings = pd.read_csv('C:/Users/jalal/Downloads/COMPER/ml-latest-small/ratings.csv')
movies = pd.read_csv('C:/Users/jalal/Downloads/COMPER/ml-latest-small/movies.csv')
print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯Ù†Ø¯: {len(ratings)} Ø±ÛŒØªÛŒÙ†Ú¯ØŒ {len(movies)} ÙÛŒÙ„Ù…")

# 2. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øªâ€ŒÙ‡Ø§ Ø¨Ø§ Ø±ÙØ¹ Ø®Ø·Ø§
print("ğŸ§® Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ...")
rating_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)

print("ğŸ‘¥ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†...")
# Ø±Ø§Ù‡ Ø­Ù„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
user_corr = rating_matrix.T.corr(method='pearson')
user_corr.index.name = 'userA'
user_corr.columns.name = 'userB'
user_sim = user_corr.stack().reset_index(name='correlation')
user_sim = user_sim[
    (user_sim['correlation'] > 0.5) & 
    (user_sim['userA'] != user_sim['userB']) &
    (user_sim['userA'] < user_sim['userB'])
].reset_index(drop=True)
print(f"âœ… {len(user_sim)} Ø¬ÙØª Ú©Ø§Ø±Ø¨Ø± Ù…Ø´Ø§Ø¨Ù‡")

print("ğŸ¬ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§...")
# Ø±Ø§Ù‡ Ø­Ù„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§
item_corr = rating_matrix.corr(method='pearson')
item_corr.index.name = 'itemA'
item_corr.columns.name = 'itemB'
item_sim = item_corr.stack().reset_index(name='correlation')
item_sim = item_sim[
    (item_sim['correlation'] > 0.5) & 
    (item_sim['itemA'] != item_sim['itemB']) &
    (item_sim['itemA'] < item_sim['itemB'])
].reset_index(drop=True)
print(f"âœ… {len(item_sim)} Ø¬ÙØª ÙÛŒÙ„Ù… Ù…Ø´Ø§Ø¨Ù‡")

# 3. Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ù‡Ù…Ú©Ø§Ø±ÛŒ
print("ğŸ•¸ï¸ Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ù‡Ù…Ú©Ø§Ø±ÛŒ...")
G = nx.Graph()

# Ø§ÙØ²ÙˆØ¯Ù† Ú¯Ø±Ù‡â€ŒÙ‡Ø§
user_nodes = ratings['userId'].unique()
item_nodes = ratings['movieId'].unique()
G.add_nodes_from(user_nodes, node_type='user')
G.add_nodes_from(item_nodes, node_type='item')
print(f"âœ… {len(user_nodes)} Ú©Ø§Ø±Ø¨Ø± Ùˆ {len(item_nodes)} ÙÛŒÙ„Ù… Ø¨Ù‡ Ú¯Ø±Ø§Ù Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù†Ø¯")

# Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø²
for _, row in tqdm(ratings.iterrows(), total=len(ratings), desc="ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø²"):
    G.add_edge(row['userId'], row['movieId'], 
               relation_type=f'Rated_{int(row["rating"])}',
               weight=row['rating'])

# Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
if not user_sim.empty:
    for _, row in tqdm(user_sim.iterrows(), total=len(user_sim), desc="Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†"):
        G.add_edge(row['userA'], row['userB'], 
                   relation_type='UserSim',
                   weight=row['correlation'])

# Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ø§Ù‡Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§
if not item_sim.empty:
    for _, row in tqdm(item_sim.iterrows(), total=len(item_sim), desc="Ø´Ø¨Ø§Ù‡Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§"):
        G.add_edge(row['itemA'], row['itemB'], 
                   relation_type='ItemSim',
                   weight=row['correlation'])

print(f"âœ… Ú¯Ø±Ø§Ù Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯: {G.number_of_nodes()} Ú¯Ø±Ù‡ØŒ {G.number_of_edges()} ÛŒØ§Ù„")

# 4. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØªØ§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
def extract_meta_paths(G, user, item, max_paths=5, max_length=3):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØªØ§ Ø¨ÛŒÙ† Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø¢ÛŒØªÙ… Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ BFS"""
    if user not in G or item not in G:
        return []
    
    try:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² BFS Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯
        paths = []
        queue = deque([(user, [user])])
        visited = set()
        
        while queue and len(paths) < max_paths:
            node, path = queue.popleft()
            visited.add(node)
            
            # Ø§Ú¯Ø± Ø¨Ù‡ Ø¢ÛŒØªÙ… Ø±Ø³ÛŒØ¯ÛŒÙ… Ùˆ Ù…Ø³ÛŒØ± Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª
            if node == item and len(path) > 1:
                paths.append(path)
                continue
                
            # Ø§Ú¯Ø± Ø·ÙˆÙ„ Ù…Ø³ÛŒØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¨ÛŒØ´ØªØ± Ø´Ø¯
            if len(path) >= max_length:
                continue
                
            # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§
            for neighbor in G.neighbors(node):
                # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø­Ù„Ù‚Ù‡
                if neighbor not in path and neighbor not in visited:
                    new_path = path + [neighbor]
                    queue.append((neighbor, new_path))
        
        return paths
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±: {e}")
        return []

# 5. Ù…Ø¯Ù„ COMPER
class COMPER(nn.Module):
    def __init__(self, num_users, num_items, num_relations, emb_dim=64, lstm_dim=64):
        super(COMPER, self).__init__()
        
        # Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ø³Ø§Ø²ÛŒ
        self.user_emb = nn.Embedding(num_users + 1, emb_dim)
        self.item_emb = nn.Embedding(num_items + 1, emb_dim)
        self.relation_emb = nn.Embedding(num_relations, emb_dim)
        self.node_type_emb = nn.Embedding(2, emb_dim)  # 0: user, 1: item
        
        # Ù„Ø§ÛŒÙ‡ LSTM
        self.lstm = nn.LSTM(3 * emb_dim, lstm_dim, batch_first=True)
        
        # Ù…Ú©Ø§Ù†ÛŒØ²Ù… ØªÙˆØ¬Ù‡
        self.attention = nn.Sequential(
            nn.Linear(lstm_dim + 2 * emb_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        
        # Ù„Ø§ÛŒÙ‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        self.fc = nn.Sequential(
            nn.Linear(lstm_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
    
    def forward(self, user, item, paths):
        # Ø¬Ø§Ø³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø¢ÛŒØªÙ…
        u_emb = self.user_emb(user)
        i_emb = self.item_emb(item)
        
        path_embs = []
        for path in paths:
            seq = []
            for i in range(len(path) - 1):
                node = path[i]
                next_node = path[i+1]
                
                # Ø¬Ø§Ø³Ø§Ø²ÛŒ Ú¯Ø±Ù‡
                if G.nodes[node].get('node_type', '') == 'user':
                    node_emb = self.user_emb(torch.tensor([node], device=user.device))
                    node_type = torch.tensor([0], device=user.device)
                else:
                    node_emb = self.item_emb(torch.tensor([node], device=user.device))
                    node_type = torch.tensor([1], device=user.device)
                
                # Ø¬Ø§Ø³Ø§Ø²ÛŒ Ø±Ø§Ø¨Ø·Ù‡
                rel_type = G.edges[node, next_node].get('relation_type', 'Rated_3')
                rel_idx = relation2idx.get(rel_type, 0)
                rel_emb = self.relation_emb(torch.tensor([rel_idx], device=user.device))
                
                # ØªØ±Ú©ÛŒØ¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
                features = torch.cat([node_emb, self.node_type_emb(node_type), rel_emb], dim=-1)
                seq.append(features)
            
            if not seq:
                continue
                
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ LSTM
            seq = torch.stack(seq).unsqueeze(0)
            _, (h_n, _) = self.lstm(seq)
            path_emb = h_n[-1]
            path_embs.append(path_emb)
        
        if not path_embs:
            return torch.zeros(1, device=user.device), torch.zeros(1, device=user.device)
            
        path_embs = torch.cat(path_embs, dim=0)
        context = torch.cat([u_emb, i_emb], dim=-1).repeat(len(path_embs), 1)
        att_input = torch.cat([path_embs, context], dim=1)
        att_scores = self.attention(att_input)
        att_weights = F.softmax(att_scores, dim=0)
        
        # ØªØ¬Ù…Ø¹ Ø¨Ø§ ØªÙˆØ¬Ù‡
        aggregated = torch.sum(att_weights * path_embs, dim=0)
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        prediction = self.fc(aggregated)
        return prediction, att_weights

# 6. Ù…Ø­ÛŒØ· ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªÙ‚ÙˆÛŒØªÛŒ
class RecSysEnv(gym.Env):
    def __init__(self, model, data, G, relation2idx):
        super(RecSysEnv, self).__init__()
        self.model = model
        self.data = data
        self.G = G
        self.relation2idx = relation2idx
        self.current_idx = 0
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(128,))
        self.action_space = spaces.MultiBinary(5)
        self.max_steps = min(500, len(data))
        self.current_step = 0
        
    def reset(self):
        self.current_idx = 0
        self.current_step = 0
        return self._get_state()
    
    def step(self, action):
        self.current_step += 1
        row = self.data.iloc[self.current_idx]
        user = torch.tensor([row['userId']], device=device)
        item = torch.tensor([row['movieId']], device=device)
        true_rating = row['rating']
        
        paths = extract_meta_paths(self.G, user.item(), item.item(), max_paths=5, max_length=3)
        selected_paths = [p for i, p in enumerate(paths) if i < len(action) and action[i] == 1]
        
        if not selected_paths and paths:
            selected_paths = paths[:3]
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„
        with torch.no_grad():
            try:
                pred, _ = self.model(user, item, selected_paths)
                rmse = torch.sqrt(F.mse_loss(pred, torch.tensor([true_rating], device=device))).item()
            except:
                rmse = 3.0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ø§Ø¯Ø§Ø´
        sid = self.compute_sid(selected_paths) if selected_paths else 0.0
        reward = -rmse + 0.5 * sid
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³
        self.current_idx = (self.current_idx + 1) % len(self.data)
        done = self.current_step >= self.max_steps
        
        return self._get_state(), reward, done, {}
    
    def _get_state(self):
        row = self.data.iloc[self.current_idx]
        user = torch.tensor([row['userId']], device=device)
        item = torch.tensor([row['movieId']], device=device)
        with torch.no_grad():
            u_emb = self.model.user_emb(user).cpu().numpy().flatten()
            i_emb = self.model.item_emb(item).cpu().numpy().flatten()
        return np.concatenate([u_emb, i_emb])
    
    def compute_sid(self, paths):
        pattern_counts = {}
        for path in paths:
            pattern = []
            for i in range(len(path) - 1):
                rel = self.G.edges[path[i], path[i+1]].get('relation_type', 'Rated_3')[:3]
                pattern.append(rel)
            pattern_str = '-'.join(pattern)
            pattern_counts[pattern_str] = pattern_counts.get(pattern_str, 0) + 1
        
        n = len(paths)
        sid = 1 - sum([count*(count-1) for count in pattern_counts.values()]) / (n*(n-1)) if n > 1 else 0
        return sid

# 7. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
print("âš™ï¸ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„...")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"âš¡ Ø¯Ø³ØªÚ¯Ø§Ù‡: {device}")

# Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„
num_users = ratings['userId'].nunique()
num_items = ratings['movieId'].nunique()
relation_types = list(set(d['relation_type'] for _, _, d in G.edges(data=True)))
relation2idx = {rel: idx for idx, rel in enumerate(relation_types)}

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)
print(f"âœ‚ï¸ ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡: Ø¢Ù…ÙˆØ²Ø´={len(train_data)}, ØªØ³Øª={len(test_data)}")

# Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„
model = COMPER(num_users, num_items, len(relation_types), emb_dim=32, lstm_dim=32).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 8. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
print("ğŸ”¥ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡...")
train_data_small = train_data.sample(frac=0.1, random_state=42)  # Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
print(f"ğŸ” Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ {len(train_data_small)} Ù†Ù…ÙˆÙ†Ù‡ (10% Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§)")

for epoch in range(1):  # ÙÙ‚Ø· ÛŒÚ© Ø¯ÙˆØ±Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    epoch_loss = 0
    no_path_count = 0
    error_count = 0
    processed_count = 0
    
    progress_bar = tqdm(train_data_small.iterrows(), total=len(train_data_small), desc=f"Ø¯ÙˆØ±Ù‡ {epoch+1}/1")
    for idx, row in progress_bar:
        try:
            user = torch.tensor([row['userId']], device=device)
            item = torch.tensor([row['movieId']], device=device)
            true_rating = torch.tensor([row['rating']], dtype=torch.float, device=device)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª
            paths = extract_meta_paths(G, user.item(), item.item(), max_paths=5, max_length=3)
            
            if not paths:
                no_path_count += 1
                continue
                
            # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
            pred, _ = model(user, item, paths)
            loss = F.mse_loss(pred, true_rating)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            processed_count += 1
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
            if idx % 100 == 0:
                progress_bar.set_postfix(
                    loss=f"{loss.item():.4f}", 
                    paths=len(paths),
                    processed=f"{processed_count}/{len(train_data_small)}"
                )
            
        except Exception as e:
            error_count += 1
            # print(f"Error: {e}")  # ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø®Ø·Ø§
    valid_samples = processed_count
    if valid_samples > 0:
        avg_loss = epoch_loss / valid_samples
    else:
        avg_loss = 0
        
    print(f"\nØ¯ÙˆØ±Ù‡ {epoch+1} - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø®Ø·Ø§: {avg_loss:.4f}")
    print(f"Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø³ÛŒØ±: {no_path_count}, Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø®Ø·Ø§: {error_count}")
    
    # Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡
    gc.collect()
    torch.cuda.empty_cache()

# 9. Ø¢Ù…ÙˆØ²Ø´ Ø¹Ø§Ù…Ù„ RL
print("ğŸ¤– Ø¢Ù…ÙˆØ²Ø´ Ø¹Ø§Ù…Ù„ RL...")
env = RecSysEnv(model, train_data_small, G, relation2idx)
env = DummyVecEnv([lambda: env])

rl_model = PPO(
    "MlpPolicy",
    env,
    verbose=0,
    learning_rate=0.0003,
    n_steps=256,
    batch_size=32,
    n_epochs=3,
    device=device
)

# Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
total_timesteps = 1000
progress_bar = tqdm(total=total_timesteps, desc="Ø¢Ù…ÙˆØ²Ø´ RL")
for i in range(total_timesteps // 100):
    rl_model.learn(total_timesteps=100)
    progress_bar.update(100)
progress_bar.close()

# 10. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
print("ğŸ§ª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„...")
def evaluate(model, data):
    predictions, truths = [], []
    no_path_count = 0
    
    for _, row in tqdm(data.iterrows(), total=len(data), desc="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ"):
        user = torch.tensor([row['userId']], device=device)
        item = torch.tensor([row['movieId']], device=device)
        true_rating = row['rating']
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª
        paths = extract_meta_paths(G, user.item(), item.item(), max_paths=5, max_length=3)
        
        if not paths:
            no_path_count += 1
            predictions.append(3.0)  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            truths.append(true_rating)
            continue
            
        with torch.no_grad():
            pred, _ = model(user, item, paths)
            predictions.append(pred.item())
            truths.append(true_rating)
    
    print(f"Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø³ÛŒØ± Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ: {no_path_count}")
    return (
        np.sqrt(mean_squared_error(truths, predictions)),
        mean_absolute_error(truths, predictions)
    )

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§ Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ú©ÙˆÚ†Ú©
test_data_small = test_data.sample(frac=0.1, random_state=42)
test_rmse, test_mae = evaluate(model, test_data_small)
print(f"âœ… Ù†ØªØ§ÛŒØ¬: RMSE={test_rmse:.4f}, MAE={test_mae:.4f}")

# 11. ØªÙˆÙ„ÛŒØ¯ ØªÙˆØ¶ÛŒØ­
print("\nğŸ­ ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆÙ†Ù‡ ØªÙˆØ¶ÛŒØ­:")
sample = test_data_small.sample(1).iloc[0]
user_id = sample['userId']
item_id = sample['movieId']
movie_title = movies[movies['movieId'] == item_id]['title'].values[0]
true_rating = sample['rating']

print(f"ğŸ‘¤ Ú©Ø§Ø±Ø¨Ø±: {user_id}, ğŸ¬ ÙÛŒÙ„Ù…: {movie_title}, â­ Ø§Ù…ØªÛŒØ§Ø² ÙˆØ§Ù‚Ø¹ÛŒ: {true_rating}")

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§
paths = extract_meta_paths(G, user_id, item_id, max_paths=10, max_length=3)
if not paths:
    print("Ù‡ÛŒÚ† Ù…Ø³ÛŒØ± ØªÙØ³ÛŒØ±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
else:
    user_tensor = torch.tensor([user_id], device=device)
    item_tensor = torch.tensor([item_id], device=device)
    pred, att_weights = model(user_tensor, item_tensor, paths)
    
    print(f"ğŸ”® Ø§Ù…ØªÛŒØ§Ø² Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡: {pred.item():.2f}")
    
    # Ù†Ù…Ø§ÛŒØ´ 3 Ù…Ø³ÛŒØ± Ø¨Ø±ØªØ±
    weights = att_weights.squeeze().cpu().detach().numpy()
    top_indices = weights.argsort()[-3:][::-1] if len(weights) > 3 else range(len(weights))
    
    print("\nğŸ’¡ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªÙØ³ÛŒØ±ÛŒ Ø¨Ø±ØªØ±:")
    for i, idx in enumerate(top_indices, 1):
        if idx >= len(paths):
            continue
            
        path = paths[idx]
        weight = weights[idx]
        explanation = []
        
        for j in range(len(path) - 1):
            from_node = path[j]
            to_node = path[j+1]
            rel = G.edges[from_node, to_node]['relation_type']
            
            if 'UserSim' in rel:
                explanation.append(f"Ú©Ø§Ø±Ø¨Ø± Ù…Ø´Ø§Ø¨Ù‡ {from_node}")
            elif 'ItemSim' in rel:
                movie_title = movies[movies['movieId'] == from_node]['title'].values[0] if from_node in movies['movieId'].values else f"ÙÛŒÙ„Ù… {from_node}"
                explanation.append(f"ÙÛŒÙ„Ù… Ù…Ø´Ø§Ø¨Ù‡ '{movie_title}'")
            elif 'Rated' in rel:
                rating = rel.split('_')[-1]
                if G.nodes[from_node].get('node_type', '') == 'user':
                    explanation.append(f"Ú©Ø§Ø±Ø¨Ø± {from_node} â†’ Ø§Ù…ØªÛŒØ§Ø² {rating}")
                else:
                    movie_title = movies[movies['movieId'] == from_node]['title'].values[0] if from_node in movies['movieId'].values else f"ÙÛŒÙ„Ù… {from_node}"
                    explanation.append(f"'{movie_title}' â†’ Ø§Ù…ØªÛŒØ§Ø² {rating}")
        
        print(f"{i}. {' â†’ '.join(explanation)} (ÙˆØ²Ù†: {weight:.4f})")