{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hct28WIaP5Qg"
   },
   "outputs": [],
   "source": [
    "# 1 – Install main dependencies\n",
    "!pip install -q --upgrade \"numpy<2.0\"  # ۱.۲۶.۴\n",
    "!pip install -q torch==2.2.0+cu118 torchtext==0.17.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -q torch_geometric torch_sparse torch_scatter torch_cluster torch_spline_conv \\\n",
    "              -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4v_fGzMoP66r",
    "outputId": "39d6385b-3247-47ab-e9ed-2bea005855a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 2 – Connect Google Drive and set paths\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "GRAPH_PATH = \"/content/drive/MyDrive/ml100k_graphs/ml100k_step3_full_graph.pt\"\n",
    "MODEL_DIR  = \"/content/drive/MyDrive/ml100k_models\"\n",
    "\n",
    "import os, torch, numpy as np, random\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_T54B1LQA7s",
    "outputId": "ecef2456-d425-4fb8-9944-e10532477948"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/edge_index.py:863: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types after AddMetaPaths → [('user', 'Rank', 'item'), ('item', 'BeRanked', 'user'), ('user', 'UserSim', 'user'), ('item', 'ItemSim', 'item'), ('user', 'memberOf', 'user_cluster'), ('user_cluster', 'contains', 'user'), ('item', 'memberOf', 'item_cluster'), ('item_cluster', 'contains', 'item'), ('user', 'metapath_0', 'user'), ('item', 'metapath_1', 'item'), ('user', 'metapath_2', 'item'), ('user', 'metapath_3', 'item'), ('user', 'metapath_4', 'item'), ('user', 'metapath_5', 'item'), ('user', 'metapath_6', 'item'), ('user', 'metapath_7', 'item')]\n"
     ]
    }
   ],
   "source": [
    "# 3 – Load graph, add self-loops, and advanced metapaths\n",
    "from torch_geometric.transforms import AddSelfLoops, AddMetaPaths\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data: HeteroData = torch.load(GRAPH_PATH)\n",
    "\n",
    "# Self-loop on all relations \n",
    "data = AddSelfLoops(attr=None)(data)\n",
    "\n",
    "# Metapaths\n",
    "metapaths = [\n",
    "    [(\"user\",\"Rank\",\"item\"), (\"item\",\"BeRanked\",\"user\")],            # U-I-U \n",
    "    [(\"item\",\"BeRanked\",\"user\"), (\"user\",\"Rank\",\"item\")],            # I-U-I \n",
    "\n",
    "    [(\"user\",\"UserSim\",\"user\"), (\"user\",\"Rank\",\"item\")],             # m0\n",
    "    [(\"user\",\"Rank\",\"item\"), (\"item\",\"ItemSim\",\"item\")],             # m1\n",
    "\n",
    "    [(\"user\",\"memberOf\",\"user_cluster\"),\n",
    "     (\"user_cluster\",\"contains\",\"user\"),\n",
    "     (\"user\",\"Rank\",\"item\")],                                        # m2\n",
    "\n",
    "    [(\"user\",\"Rank\",\"item\"),\n",
    "     (\"item\",\"memberOf\",\"item_cluster\"),\n",
    "     (\"item_cluster\",\"contains\",\"item\")],                            # m3\n",
    "\n",
    "    [(\"user\",\"UserSim\",\"user\"),\n",
    "     (\"user\",\"Rank\",\"item\"),\n",
    "     (\"item\",\"ItemSim\",\"item\")],                                     # m4\n",
    "\n",
    "    [(\"user\",\"memberOf\",\"user_cluster\"),\n",
    "     (\"user_cluster\",\"contains\",\"user\"),\n",
    "     (\"user\",\"Rank\",\"item\"),\n",
    "     (\"item\",\"ItemSim\",\"item\")]                                      # m5\n",
    "]\n",
    "\n",
    "data = AddMetaPaths(metapaths, max_sample=300)(data)\n",
    "print(\"Edge types after AddMetaPaths →\", data.edge_types)\n",
    "data = data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hERT8qdNquu",
    "outputId": "b52f3c3f-93f6-4799-d63d-3d2c55895067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edges: 95,000  |  Test edges: 5,000\n"
     ]
    }
   ],
   "source": [
    "# 4 – Prepare train / test indices for the Rank relation\n",
    "rank_rel = (\"user\",\"Rank\",\"item\")\n",
    "\n",
    "ei          = data[rank_rel].edge_index\n",
    "ratings_all = data[rank_rel].rating.to(device)\n",
    "\n",
    "train_mask  = data[rank_rel].train_mask\n",
    "test_mask   = data[rank_rel].test_mask\n",
    "\n",
    "train_src, train_dst = ei[:, train_mask]\n",
    "test_src , test_dst  = ei[:, test_mask]\n",
    "\n",
    "y_train = ratings_all[train_mask]\n",
    "y_test  = ratings_all[test_mask]\n",
    "\n",
    "print(f\"Train edges: {y_train.numel():,}  |  Test edges: {y_test.numel():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tfP74PONsZy",
    "outputId": "e91d7089-2790-4b5e-d8b8-67b3df39928e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready ✔ (edge-dropout فعال)\n"
     ]
    }
   ],
   "source": [
    "# 5 – Three-layer HAN architecture + custom edge-dropout\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HANConv\n",
    "from torch_geometric.utils import dropout_edge        \n",
    "\n",
    "class HANRecommender(nn.Module):\n",
    "    def __init__(self, metadata, in_dims, hidden=128, out=128,\n",
    "                 heads=(8, 4, 1), dropout=0.4, edge_p=0.2):\n",
    "        super().__init__()\n",
    "        self.edge_p = edge_p         # Edge dropout probability\n",
    "\n",
    "        self.h1 = HANConv(in_dims, hidden, metadata,\n",
    "                          heads=heads[0], dropout=dropout)\n",
    "        self.h2 = HANConv(-1, hidden, metadata,\n",
    "                          heads=heads[1], dropout=dropout)\n",
    "        self.h3 = HANConv(-1, out,    metadata,\n",
    "                          heads=heads[2], dropout=dropout)\n",
    "\n",
    "        self.link = nn.Sequential(\n",
    "            nn.Linear(2*out, out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(out, 1)\n",
    "        )\n",
    "\n",
    "    def _edge_dropout(self, edge_index_dict):\n",
    "        \"\"\"Apply edge dropout to each relation.\"\"\"\n",
    "        if not self.training or self.edge_p == 0:\n",
    "            return edge_index_dict\n",
    "        out = {}\n",
    "        for rel, ei in edge_index_dict.items():\n",
    "            ei_dropped, _ = dropout_edge(ei, p=self.edge_p, force_undirected=False)\n",
    "            out[rel] = ei_dropped\n",
    "        return out\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, src, dst):\n",
    "        edge_index_dict = self._edge_dropout(edge_index_dict)\n",
    "\n",
    "        x_dict = self.h1(x_dict, edge_index_dict)\n",
    "        x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
    "\n",
    "        x_dict = self.h2(x_dict, edge_index_dict)\n",
    "        x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
    "\n",
    "        x_dict = self.h3(x_dict, edge_index_dict)\n",
    "\n",
    "        h_u, h_v = x_dict[\"user\"][src], x_dict[\"item\"][dst]\n",
    "        return self.link(torch.cat([h_u, h_v], dim=-1)).squeeze()\n",
    "\n",
    "# Input dimensions for each node type\n",
    "in_dims = {nt: data[nt].num_features for nt in data.node_types}\n",
    "\n",
    "model = HANRecommender(data.metadata(), in_dims).to(device)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-5)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=50)\n",
    "print(\"Model ready ✔\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyew5RM6Ntor",
    "outputId": "e5470c32-83ff-4bdd-cd93-74a07062c2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E001 | trainloss 1.438 | val RMSE 1.2032\n",
      "Early stop ◀\n"
     ]
    }
   ],
   "source": [
    "# Training with Early-Stopping and validation\n",
    "from math import sqrt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Split Train into Train/Val \n",
    "train_mask = data[rank_rel].train_mask.bool()          # (100 000,)\n",
    "train_idx  = torch.nonzero(train_mask, as_tuple=False).view(-1)\n",
    "n_val      = int(0.10 * train_idx.numel())             # 10٪\n",
    "\n",
    "# Randomly select validation indices\n",
    "val_sel    = train_idx[torch.randperm(train_idx.numel(), generator=torch.Generator().manual_seed(42))[:n_val]]\n",
    "val_mask   = torch.zeros_like(train_mask)\n",
    "val_mask[val_sel] = True\n",
    "\n",
    "# Final masks\n",
    "train_sub = train_mask & ~val_mask\n",
    "val_sub   = val_mask\n",
    "\n",
    "train_src_, train_dst_ = ei[:, train_sub]\n",
    "val_src_,   val_dst_   = ei[:, val_sub]\n",
    "\n",
    "y_train = ratings_all[train_sub]\n",
    "y_val   = ratings_all[val_sub]\n",
    "\n",
    "# Training loop\n",
    "best_rmse, patience, PATIENCE = 1e9, 0, 8   # early-stop\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    pred = model(data.x_dict, data.edge_index_dict, train_src_, train_dst_)\n",
    "    loss = F.mse_loss(pred, y_train)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "    opt.step()\n",
    "    sched.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        p_val   = model(data.x_dict, data.edge_index_dict, val_src_, val_dst_)\n",
    "        rmse_val = sqrt(F.mse_loss(p_val, y_val).item())\n",
    "\n",
    "    # ─ Early-Stopping\n",
    "    if rmse_val < best_rmse - 1e-3:\n",
    "        best_rmse, patience = rmse_val, 0\n",
    "        torch.save(model.state_dict(), f\"{MODEL_DIR}/best_han.pt\")\n",
    "    else:\n",
    "        patience += 1\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"E{epoch:03d} | trainloss {loss.item():.3f} | val RMSE {rmse_val:.4f}\")\n",
    "\n",
    "    if patience >= PATIENCE:\n",
    "        print(\"Early stop ◀\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSSbREiLNvFz",
    "outputId": "544193bd-6ce7-40f9-d4ed-a8c39488ec05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚  Final  →  RMSE = 1.1547   |   MAE = 0.9406\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test\n",
    "best = HANRecommender(data.metadata(), in_dims).to(device)\n",
    "best.load_state_dict(torch.load(f\"{MODEL_DIR}/best_han.pt\"))\n",
    "best.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    p_test = best(data.x_dict, data.edge_index_dict, test_src, test_dst)\n",
    "    rmse   = sqrt(F.mse_loss(p_test, y_test).item())\n",
    "    mae    = torch.mean(torch.abs(p_test - y_test)).item()\n",
    "\n",
    "print(f\"🔚  Final  →  RMSE = {rmse:.4f}   |   MAE = {mae:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
